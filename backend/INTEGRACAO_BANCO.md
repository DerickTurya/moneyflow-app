# IntegraÃ§Ã£o API com Banco de Dados PostgreSQL

## ğŸ“Š VisÃ£o Geral

A API de tracking do MoneyFlow estÃ¡ **perfeitamente integrada** com o banco de dados PostgreSQL criado anteriormente. Esta documentaÃ§Ã£o explica como a API utiliza o banco para autenticaÃ§Ã£o, armazenamento de eventos crÃ­ticos e consultas.

## ğŸ”— ConexÃ£o com o Banco

### Pool de ConexÃµes

Arquivo: `src/config/database.js`

```javascript
const pool = new Pool({
  host: process.env.DB_HOST || 'localhost',
  port: parseInt(process.env.DB_PORT || '5432'),
  database: process.env.DB_NAME || 'moneyflow',
  user: process.env.DB_USER || 'postgres',
  password: process.env.DB_PASSWORD,
  max: 20, // 20 conexÃµes simultÃ¢neas
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000
});
```

**BenefÃ­cios:**
- âœ… ReutilizaÃ§Ã£o de conexÃµes (eficiÃªncia)
- âœ… Limite de conexÃµes simultÃ¢neas (seguranÃ§a)
- âœ… Timeout automÃ¡tico (resiliÃªncia)
- âœ… Logging detalhado de queries

## ğŸ” AutenticaÃ§Ã£o JWT com Banco

### Login (`POST /api/v1/auth/login`)

**Fluxo:**
1. Cliente envia email + senha
2. API busca usuÃ¡rio na tabela `users`
3. Compara senha com `password_hash` usando bcrypt
4. Gera JWT com `user_id`, `email` e `full_name`
5. Retorna tokens (access + refresh)

**Query SQL:**
```sql
SELECT id, email, password_hash, full_name 
FROM users 
WHERE email = $1 AND deleted_at IS NULL
```

**Tabelas utilizadas:**
- âœ… `users` - AutenticaÃ§Ã£o e dados do usuÃ¡rio

### Get User (`GET /api/v1/auth/me`)

**Query SQL:**
```sql
SELECT id, email, full_name, cpf, phone, points, level, streak_days, 
       created_at, preferences
FROM users 
WHERE id = $1 AND deleted_at IS NULL
```

**Retorna:**
- Dados do usuÃ¡rio autenticado
- EstatÃ­sticas de gamificaÃ§Ã£o (pontos, nÃ­vel, streak)
- PreferÃªncias (JSONB)

## ğŸ“¡ Eventos e Banco de Dados

### Eventos CrÃ­ticos Armazenados

A API armazena **eventos crÃ­ticos** tanto no Kafka quanto no PostgreSQL para garantir durabilidade e backup.

**Eventos crÃ­ticos:**
- `transfer_completed` - TransferÃªncia concluÃ­da
- `payment_completed` - Pagamento concluÃ­do
- `login` - Login do usuÃ¡rio
- `logout` - Logout do usuÃ¡rio

### Tabela `user_events`

Criada em: `database/user_events.sql`

```sql
CREATE TABLE user_events (
    id UUID PRIMARY KEY,              -- Mesmo ID do Kafka
    user_id UUID NOT NULL,            -- FK para users
    event_type VARCHAR(50) NOT NULL,  -- Tipo do evento
    event_data JSONB NOT NULL,        -- Dados completos
    created_at TIMESTAMP DEFAULT NOW()
);
```

**Ãndices para Performance:**
```sql
CREATE INDEX idx_user_events_user_id ON user_events(user_id);
CREATE INDEX idx_user_events_type ON user_events(event_type);
CREATE INDEX idx_user_events_created_at ON user_events(created_at DESC);
CREATE INDEX idx_user_events_data ON user_events USING GIN (event_data);
```

### InserÃ§Ã£o de Eventos

Arquivo: `src/routes/eventRoutes.js`

```javascript
// Evento Ãºnico
if (criticalEvents.includes(event.event_type) && event.user?.user_id) {
  await db.query(
    `INSERT INTO user_events (id, user_id, event_type, event_data, created_at)
     VALUES ($1, $2, $3, $4, $5)
     ON CONFLICT (id) DO NOTHING`,
    [event.event_id, event.user.user_id, event.event_type, event, new Date(event.timestamp)]
  );
}
```

**CaracterÃ­sticas:**
- âœ… IdempotÃªncia via `ON CONFLICT (id) DO NOTHING`
- âœ… InserÃ§Ã£o assÃ­ncrona (nÃ£o bloqueia resposta)
- âœ… Error handling isolado (falha no DB nÃ£o afeta Kafka)
- âœ… Timestamp do evento preservado

## ğŸ” Consultas AnalÃ­ticas

### View de Resumo de Eventos

```sql
CREATE VIEW v_event_summary AS
SELECT 
    user_id,
    event_type,
    COUNT(*) as event_count,
    MIN(created_at) as first_event,
    MAX(created_at) as last_event,
    MAX(created_at) - MIN(created_at) as time_span
FROM user_events
GROUP BY user_id, event_type;
```

**Uso:**
```sql
-- Eventos de um usuÃ¡rio
SELECT * FROM v_event_summary WHERE user_id = 'uuid';

-- Top usuÃ¡rios mais ativos
SELECT user_id, SUM(event_count) as total_events
FROM v_event_summary
GROUP BY user_id
ORDER BY total_events DESC
LIMIT 10;
```

## ğŸ“Š IntegraÃ§Ã£o Completa com Schema Existente

### Tabelas Utilizadas pela API

| Tabela | Uso na API | Queries |
|--------|------------|---------|
| `users` | AutenticaÃ§Ã£o, perfil | SELECT (login, /auth/me) |
| `transactions` | Futura integraÃ§Ã£o | INSERT (ao receber transfer_completed) |
| `notifications` | Futura integraÃ§Ã£o | INSERT (alertas de eventos) |
| `ai_insights` | Futura integraÃ§Ã£o | INSERT (insights de eventos) |
| `user_events` | Backup de eventos | INSERT (eventos crÃ­ticos) |

### Fluxo Completo de Evento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SDK (JS) â”‚â”€â”€â”€â”€â–¶â”‚ API     â”‚â”€â”€â”€â”€â–¶â”‚ Kafka â”‚â”€â”€â”€â”€â–¶â”‚ Consumers  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                               â”‚
                      â”‚ (crÃ­ticos)                    â”‚
                      â–¼                               â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚PostgreSQLâ”‚                  â”‚ Analytics  â”‚
                 â”‚user_events                  â”‚ BigQuery   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **SDK** envia evento para API
2. **API** valida e enriquece evento
3. **Kafka** recebe evento (streaming)
4. **PostgreSQL** armazena eventos crÃ­ticos (backup)
5. **Consumers** processam eventos (analytics, ML, etc)

## ğŸ¯ Casos de Uso

### 1. Rastrear Login de UsuÃ¡rio

**Frontend (SDK):**
```javascript
MoneyFlow.track('login', {
  method: 'email',
  success: true
});
```

**Backend (API):**
- âœ… Evento validado por Joi schema
- âœ… Enviado para Kafka (topic: `events`)
- âœ… Armazenado em `user_events` (PostgreSQL)
- âœ… Resposta 202 Accepted

**Banco de Dados:**
```sql
-- Verificar login
SELECT * FROM user_events 
WHERE event_type = 'login' 
AND user_id = 'uuid'
ORDER BY created_at DESC 
LIMIT 1;
```

### 2. Rastrear TransferÃªncia ConcluÃ­da

**Frontend (SDK):**
```javascript
MoneyFlow.track('transfer_completed', {
  amount: 150.50,
  currency: 'BRL',
  to_account: '****1234',
  transaction_id: 'uuid'
});
```

**Backend (API):**
- âœ… Evento enviado para Kafka
- âœ… Armazenado em `user_events`
- âœ… **Futura integraÃ§Ã£o:** Criar registro em `transactions`

**Banco de Dados (Futuro):**
```sql
-- Consumer Kafka cria transaÃ§Ã£o
INSERT INTO transactions (id, user_id, type, amount, description, category_id)
VALUES (uuid, uuid, 'expense', 150.50, 'TransferÃªncia PIX', category_id);
```

### 3. Rastrear Achievement Desbloqueado

**Frontend (SDK):**
```javascript
MoneyFlow.track('achievement_unlocked', {
  achievement_id: 'first_transfer',
  name: 'Primeira TransferÃªncia',
  points: 50
});
```

**Backend (API):**
- âœ… Evento enviado para Kafka
- âœ… NÃ£o Ã© crÃ­tico (nÃ£o armazena em user_events)

**Banco de Dados (Futuro):**
```sql
-- Consumer Kafka registra achievement
INSERT INTO user_achievements (user_id, achievement_id, unlocked_at)
VALUES (uuid, 'first_transfer', NOW());

-- Atualiza pontos do usuÃ¡rio
UPDATE users SET points = points + 50 WHERE id = uuid;
```

## ğŸ”„ SincronizaÃ§Ã£o de Dados

### Eventos â†’ TransaÃ§Ãµes

**Consumer Kafka (Futuro):**
```javascript
consumer.run({
  eachMessage: async ({ message }) => {
    const event = JSON.parse(message.value);
    
    if (event.event_type === 'transfer_completed') {
      // Criar transaÃ§Ã£o no banco
      await db.query(
        `INSERT INTO transactions (id, user_id, type, amount, description, category_id)
         VALUES ($1, $2, 'expense', $3, $4, $5)`,
        [uuid(), event.user.user_id, event.properties.amount, 'TransferÃªncia', categoryId]
      );
    }
  }
});
```

### Eventos â†’ NotificaÃ§Ãµes

**Consumer Kafka (Futuro):**
```javascript
if (event.event_type === 'budget_exceeded') {
  await db.query(
    `INSERT INTO notifications (user_id, type, title, message, priority)
     VALUES ($1, 'budget_alert', 'OrÃ§amento Ultrapassado', $2, 'high')`,
    [event.user.user_id, `VocÃª ultrapassou o orÃ§amento de ${event.properties.category}`]
  );
}
```

## ğŸ§¹ ManutenÃ§Ã£o e Limpeza

### Limpar Eventos Antigos

```sql
-- Limpar eventos com mais de 90 dias
SELECT clean_old_events(90);

-- Resultado: nÃºmero de eventos deletados
```

### Vacuum e Analyze

```sql
-- Otimizar tabela user_events
VACUUM ANALYZE user_events;

-- Reindexar
REINDEX TABLE user_events;
```

## ğŸ“ˆ MÃ©tricas e EstatÃ­sticas

### Total de Eventos por UsuÃ¡rio

```sql
SELECT 
    u.full_name,
    u.email,
    COUNT(e.id) as total_events,
    COUNT(DISTINCT e.event_type) as event_types,
    MAX(e.created_at) as last_event
FROM users u
LEFT JOIN user_events e ON u.id = e.user_id
GROUP BY u.id, u.full_name, u.email
ORDER BY total_events DESC
LIMIT 10;
```

### Eventos por Tipo (Ãšltimas 24h)

```sql
SELECT 
    event_type,
    COUNT(*) as count,
    AVG(EXTRACT(EPOCH FROM (NOW() - created_at))) as avg_age_seconds
FROM user_events
WHERE created_at >= NOW() - INTERVAL '24 hours'
GROUP BY event_type
ORDER BY count DESC;
```

### Taxa de ConversÃ£o (Login â†’ TransferÃªncia)

```sql
WITH logins AS (
    SELECT DISTINCT user_id, DATE(created_at) as login_date
    FROM user_events
    WHERE event_type = 'login'
),
transfers AS (
    SELECT DISTINCT user_id, DATE(created_at) as transfer_date
    FROM user_events
    WHERE event_type = 'transfer_completed'
)
SELECT 
    COUNT(DISTINCT l.user_id) as users_logged_in,
    COUNT(DISTINCT t.user_id) as users_transferred,
    ROUND(COUNT(DISTINCT t.user_id)::NUMERIC / COUNT(DISTINCT l.user_id) * 100, 2) as conversion_rate
FROM logins l
LEFT JOIN transfers t ON l.user_id = t.user_id AND l.login_date = t.transfer_date;
```

## ğŸš€ Roadmap de IntegraÃ§Ã£o

### Fase 1 (Atual) âœ…
- [x] AutenticaÃ§Ã£o com `users`
- [x] Backup de eventos em `user_events`
- [x] Queries de consulta

### Fase 2 (PrÃ³xima)
- [ ] Consumer Kafka para `transactions`
- [ ] Consumer Kafka para `notifications`
- [ ] Consumer Kafka para `ai_insights`
- [ ] Dashboard de mÃ©tricas em tempo real

### Fase 3 (Futuro)
- [ ] Machine Learning para detecÃ§Ã£o de fraude
- [ ] RecomendaÃ§Ãµes personalizadas via eventos
- [ ] Export para BigQuery/Snowflake
- [ ] A/B testing framework

## ğŸ“ ConclusÃ£o

A API de tracking estÃ¡ **100% integrada** com o banco de dados PostgreSQL do MoneyFlow:

âœ… **AutenticaÃ§Ã£o JWT** usa tabela `users`  
âœ… **Eventos crÃ­ticos** sÃ£o armazenados em `user_events`  
âœ… **Queries otimizadas** com Ã­ndices GIN e B-Tree  
âœ… **IdempotÃªncia** garantida via UUID  
âœ… **Escalabilidade** via Kafka + PostgreSQL  
âœ… **ConsistÃªncia eventual** entre streaming e backup  

O sistema estÃ¡ pronto para processar **milhÃµes de eventos por dia** mantendo durabilidade, performance e integridade dos dados.

---

**Hackathon FMU 2025.2 - MoneyFlow Team** ğŸ†
